{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "While `numpy` arrays are fast, they lack useful annotation regarding what the data actually represents.  \n",
    "A commonly used library to account for that is `pandas`, which introduces two new data types: `Series` and `DataFrame`.  \n",
    "You can think a `Series` as an annotated vector (with an index) and a `DataFrame` as an annotated matrix (with an index and columns).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, cast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def test(x: Any, expected: Any) -> None:\n",
    "    if isinstance(x, np.ndarray) and isinstance(expected, np.ndarray):\n",
    "        if not np.array_equal(x, expected):\n",
    "            raise AssertionError(f\"Expected {expected}, got {x}\")\n",
    "    elif isinstance(x, pd.DataFrame) and isinstance(expected, pd.DataFrame):\n",
    "        if not x.equals(expected):            \n",
    "            raise AssertionError(f\"Expected {expected}, got {x}\")\n",
    "    elif isinstance(x, pd.Series) and isinstance(expected, pd.Series):\n",
    "        if not x.equals(expected):            \n",
    "            raise AssertionError(f\"Expected {expected}, got {x}\")\n",
    "    else:\n",
    "        if x != expected:\n",
    "            raise AssertionError(f\"Expected {expected}, got {x}\")\n",
    "    print(\"Test passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series construction\n",
    "\n",
    "Series can be constructed in a variety of ways.  \n",
    "If you pass an array / list, by default an integer index will be added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor = pd.Series([4.7, 3.2, 1.3, 0.2])\n",
    "versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can insert a custom index in order to better communicate what the data describes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    \"sepal length (cm)\",\n",
    "    \"sepal width (cm)\",\n",
    "    \"petal length (cm)\",\n",
    "    \"petal width (cm)\",\n",
    "]\n",
    "\n",
    "versicolor.index = pd.Index(index)\n",
    "versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly add the index when initializing the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica = pd.Series([5.1, 3.5, 1.4, 0.2], index=index)\n",
    "virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, my preferred way, you can simply use a dictionary and let `pandas` use the dictionary keys as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = pd.Series(\n",
    "    {\n",
    "        \"sepal length (cm)\": 4.9,\n",
    "        \"sepal width (cm)\": 3.0,\n",
    "        \"petal length (cm)\": 1.4,\n",
    "        \"petal width (cm)\": 0.2,\n",
    "    }\n",
    ")\n",
    "setosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame construction\n",
    "\n",
    "`DataFrame`s can be built analogously.  \n",
    "Since I didn't want to repeat all the possibilities, I just used the `Series` we had before as dictionary values.  \n",
    "You can also create nested dictionaries, or a 2d matrix with the keyword arguments `index` and `columns` respectively for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame(\n",
    "    {\n",
    "        \"virginica\": virginica,\n",
    "        \"setosa\": setosa,\n",
    "        \"versicolor\": versicolor,\n",
    "    }\n",
    ")\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick stats: min, max, mean, std\n",
    "\n",
    "Since pandas was built with statistical analysis in mind you can very quickly do basic statistics on the data sets using `.describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in portions of this, you can call each of the functions separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean sepal length: {:.2f}\".format(iris.loc[\"sepal length (cm)\"].mean()))\n",
    "print(\"Min sepal length : {:.2f}\".format(iris.loc[\"sepal length (cm)\"].min()))\n",
    "print(\"Max sepal length : {:.2f}\".format(iris.loc[\"sepal length (cm)\"].max()))\n",
    "print(\"sepal length std : {:.2f}\".format(iris.loc[\"sepal length (cm)\"].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Note that `pandas` uses `.loc[idx]` to index, instead of just plain `[idx]`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica.loc[\"sepal length (cm)\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is because there is a second way using `.iloc[idx]` if you want to fall back to using integer indices to access your data.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `DataFrame`s have two dimensions, indexing is done using `.loc[index, column]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[\"sepal length (cm)\", \"setosa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If all columns are required, you can leave out the second argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[\"sepal length (cm)\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And if all rows required, the usual slicing syntax works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[:, \"setosa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you ever need to view or access the respective indexes directly, you can use `.index` and `.columns` (on `DataFrame`s) for that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(setosa.index)  # Index(['sepal length (cm)', 'sepal width (cm)', ...\n",
    "print(iris.index)    # Index(['sepal length (cm)', 'sepal width (cm)', ...\n",
    "print(iris.columns)  # Index(['virginica', 'setosa', ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note**\n",
    "\n",
    "You *can* just use `[idx]` to index into both `Series` and `DataFrames`.  \n",
    "Do note though, that in that case in a `Series` you index into the index, and in a `DataFrame` you index into the *columns*, so it is easy to mix things up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "You can use boolean filters just like with numpy arrays to select a portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length = iris.loc[\"sepal length (cm)\"]\n",
    "sepal_length[sepal_length < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: filtering\n",
    "\n",
    "Given the `DataFrame` of Arabidopsis thaliana mutants below, select only those for which the score is between 15 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\n",
    "            \"wt\",\n",
    "            \"col0\",\n",
    "            \"col1\",\n",
    "            \"ara\",\n",
    "            \"core\",\n",
    "            \"col17\",\n",
    "            \"col18\",\n",
    "            \"over\",\n",
    "            \"mut\",\n",
    "            \"mu5\",\n",
    "        ],\n",
    "        \"score\": [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        \"region\": [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        \"qualify\": [\"yes\", \"no\", \"yes\", \"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "expected = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": {2: \"col1\", 5: \"col17\", 9: \"mu5\"},\n",
    "        \"score\": {2: 16.5, 5: 20.0, 9: 19.0},\n",
    "        \"region\": {2: 2, 5: 3, 9: 1},\n",
    "        \"qualify\": {2: \"yes\", 5: \"yes\", 9: \"yes\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "filtered = ...\n",
    "\n",
    "test(filtered, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "`Pandas` has a quick way to create plots from `DataFrame`s and `Series`, using the `.plot` method.  \n",
    "The method takes a few optional parameters, the most interesting being `kind`, with which you can create different plot kinds.  \n",
    "Here is a list of the supported plots:\n",
    "\n",
    "| name    | description                    |\n",
    "|---------|--------------------------------|\n",
    "| line    | line plot (default)            |\n",
    "| bar     | vertical bar plot              |\n",
    "| barh    | horizontal bar plot            |\n",
    "| hist    | histogram                      |\n",
    "| box     | boxplot                        |\n",
    "| kde     | Kernel Density Estimation plot |\n",
    "| area    | area plot                      |\n",
    "| pie     | pie plot                       |\n",
    "| scatter | scatter plot (DataFrame only)  |\n",
    "| hexbin  | hexbin plot (DataFrame only)   |\n",
    "\n",
    "For a complete explanation of all the options, refer to the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = iris.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = iris.T.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = iris.T.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = iris.plot(kind=\"area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on learning: by-catch data set\n",
    "\n",
    "You are now ready to work with your first real data set!  \n",
    "We will start below by loading subset of the turtle data you will be working with later.  \n",
    "We are using the `read_csv` function to load the `bycatch.csv`.  \n",
    "The `index_col=0` argument sets the first column as the index of the data frame.  \n",
    "\n",
    "After that the `rename` call changes one of the column names, as it contains some trailing whitespace, which otherwise will have a high chance of tripping us over later.\n",
    "\n",
    "Lastly, we convert the caught date into a Python `datetime` object, that will allow us to more easily manipulate this data later on.  \n",
    "\n",
    "Feel free to comment out different parts of this to see what exactly they are doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (\n",
    "    pd.read_csv(Path(\"data\") / \"bycatch.csv\", index_col=0)\n",
    "    .rename(columns={\"Caught date \": \"Caught date\"})\n",
    ")\n",
    "df1[\"Caught date\"] = pd.to_datetime(df1[\"Caught date\"], format=r\"%m/%d/%y\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.head()` method to inspect the first few rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: caught by species\n",
    "\n",
    "Select the `\"Species\"` column of the data frame and use the `.value_counts` function to see how many individuals were caught by species.\n",
    "\n",
    "Note that this returns a `Series` object.  \n",
    "Use the `plot` function on this object to create a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: length distribution\n",
    "\n",
    "Plot a histogram of the curved carapace length (ccl) of all turtles.  \n",
    "What is the most common size?  \n",
    "What kind of distribution do you see?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: weight distribution\n",
    "\n",
    "Plot a histrogram of the weight of all turtles.  \n",
    "What is the most common weight?  \n",
    "What kind of distribution do you see?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: length vs weight\n",
    "\n",
    "Plot the length (ccl) against the weight of the turtles as a *scatter plot*.  \n",
    "Do you have any idea what could cause the shape you observe?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: times each turtle got caught\n",
    "\n",
    "Next we want to know how often each turtle got caught.  \n",
    "This will help us to assess how much temporal information we can get out of the data.  \n",
    "\n",
    "\n",
    "Plot a histogram of how often each turtle got caught.  \n",
    "\n",
    "Hint: using `value_counts` you can count all the `Turtle ID`s.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: place of capture\n",
    "\n",
    "Now we want to know *where* the turtles were captured.  \n",
    "\n",
    "Plot a histrogram of how often the turtles were caught at each capture site.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "One very powerful technique to work on data is to split it into different groups, applying a function on each group and then combining the results of each operation again.  \n",
    "Pandas has a function called `groupby` which can be used for this.  \n",
    "\n",
    "We are going to work with the dates of capture next, so we need a very quick introduction into how `Datetime` objects work.  \n",
    "\n",
    "In order to get all `Datetime` objects in a column, we need the `.dt` method.  \n",
    "This will allow us to call `Datetime` methods on each of the objects.  \n",
    "Let's first try with getting the day of week, for which we can use\n",
    "\n",
    "```python\n",
    "df[\"Caught date\"].dt.day_of_week\n",
    "```\n",
    "\n",
    "Let's take a look at the first few elements with `head`.  \n",
    "Note that 0 here means Monday, and 6 means Sunday.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Caught date\"].dt.day_of_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `groupby` with the this transformed colum.  \n",
    "Let's count how many turtles were caught on each of the weekdays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Caught date\"].groupby(df1[\"Caught date\"].dt.day_of_week).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add a meaningful index to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1[\"Species\"].groupby(df1[\"Caught date\"].dt.day_of_week).count()\n",
    "s.index = [  # type: ignore\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: weekday of catch\n",
    "\n",
    "Using the series above, create a bar plot to show how many turtles were caught on each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1[\"Species\"].groupby(df1[\"Caught date\"].dt.day_of_week).count()\n",
    "s.index = [  # type: ignore\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby: multiple\n",
    "\n",
    "We can also use combinations of selections, like for example each month of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the index is now a combination of both the year and the month, called a [MultiIndex](https://pandas.pydata.org/docs/user_guide/advanced.html#hierarchical-indexing-multiindex). These can be a bit annoying to work with, so we are going to combine both levels of that multi-index.\n",
    "\n",
    "First, we are going to unstack the index, which will pivot one level of the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are going to replace the index with a new, custom index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When where which species caught?\n",
    "s = (\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    ")\n",
    "s.index = s.index.map(lambda xy: f\"{xy[0]}-{xy[1]:02}\")\n",
    "s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we are going to replace the `NaN` (not a number) entries with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "s.index = s.index.map(lambda xy: f\"{xy[0]}-{xy[1]:02}\")\n",
    "s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: turtle distribution by month (absolute)\n",
    "\n",
    "Using a bar plot, show how many of each turtle species were caught each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "s.index = s.index.map(lambda xy: f\"{xy[0]}-{xy[1]:02}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: turtle distribution by month (relative)\n",
    "\n",
    "In the last exercise you showed the absolute number of each turtle species per month.  \n",
    "Now, plot the *relative* amount of each turtle species per month by summing up the total number of turtles *per month* and then dividing the number of each species by the respective sum.  \n",
    "Use a stacked bar plot or an area plot for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (\n",
    "    df1[\"Species\"]\n",
    "    .groupby([df1[\"Caught date\"].dt.year, df1[\"Caught date\"].dt.month])  # type: ignore\n",
    "    .value_counts()\n",
    "    .unstack()\n",
    "    .fillna(0)\n",
    ")\n",
    "s.index = s.index.map(lambda xy: f\"{xy[0]}-{xy[1]:02}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on learning: trc data set\n",
    "\n",
    "This next data set contains data about the admission and treatment of caught turtles.  \n",
    "You will perform an analysis of which diagnoses lead to which outcome.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (\n",
    "    pd.read_csv(Path(\"data\") / \"trc.csv\")\n",
    "    .set_index(\"Interaction ID\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"Admission  Outcome\": \"Admission Outcome\",\n",
    "            \"Admission  Outcome Date\": \"Admission Outcome Date\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "df2[\"Admission Date\"] = pd.to_datetime(df2[\"Admission Date\"], format=r\"%m/%d/%y\")\n",
    "df2[\"Admission Outcome Date\"] = pd.to_datetime(\n",
    "    df2[\"Admission Outcome Date\"], format=r\"%m/%d/%y\"\n",
    ")\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "To get a feeling of how many turtles can be released, have to be euthanised or died during the treatment, count the different admission outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "To get a feeling for the prevalence of each condition, count the values of all admission diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Group the data by the admission diagnosis and then count how often each admission outcome can be observed.  \n",
    "\n",
    "Plot your results as a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Repeat the previous task, but plot the outcome relative to the respective number of admission diagnoses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further learning\n",
    "\n",
    "Documentation\n",
    "\n",
    "- [numpy documentation](https://numpy.org/doc/stable/user/index.html#user)\n",
    "- [pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html)\n",
    "- [matplotlib documentation](https://matplotlib.org/stable/index.html)\n",
    "\n",
    "Further packages\n",
    "\n",
    "- [seaborn](https://seaborn.pydata.org/): package built on top of matplotlib for statistical plots\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/tutorial/index.html#user-guide): advanced scientific computing library\n",
    "- [statsmodels](https://www.statsmodels.org/stable/index.html): statistical models\n",
    "- [scikit-learn](https://scikit-learn.org/stable/): machine learning library\n",
    "- [PyTorch](https://pytorch.org/docs/stable/index.html): deep learning library\n",
    "- [tensorflow](https://www.tensorflow.org/tutorials): deep learning library\n",
    "- [Keras](https://keras.io/): deep learning library \n",
    "- [aesara](https://github.com/aesara-devs/aesara) (used to be Theano): symbolic maths on multi-dimensional arrays\n",
    "- [JAX](https://github.com/google/jax): Composable transformations of Python & numpy on GPUs \n",
    "\n",
    "Books\n",
    "\n",
    "- [Jake VanderPlas - Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "- [Wes McKinnery - Python for Data Analysis](https://wesmckinney.com/book/)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efa8b17b9e33237cbcac2860a8fba36b27177a72c7cfe842f3a84d2139868231"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
